{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "012693f1",
      "metadata": {
        "id": "012693f1"
      },
      "source": [
        "\n",
        "## Módulos de Inserção\n",
        "\n",
        "Os módulos de inserção, ou *Insertion Modules*, são uma arquitetura de redes neurais convolucionais (CNNs) projetada para capturar características em diferentes escalas dentro de uma imagem. Vamos definir o módulo `InsercaoModulo`, que realiza as seguintes operações:\n",
        "\n",
        "1. **Redução de Dimensão**: Utiliza uma convolução 1x1 para reduzir o número de canais de entrada, facilitando a integração de diferentes características.\n",
        "2. **Convoluções**:\n",
        "   - **Convolução 1x1**: Captura características de baixo nível mantendo a dimensionalidade dos canais.\n",
        "   - **Convolução 3x3**: Extrai características espaciais mais detalhadas.\n",
        "   - **Convolução 5x5**: Captura padrões mais amplos e complexos.\n",
        "3. **Max Pooling**: Aplica uma operação de max pooling 3x3 para reduzir a resolução espacial, seguida por uma convolução 1x1 para manter a dimensionalidade dos canais.\n",
        "4. **Concatenação**: Combina as saídas das operações anteriores ao longo da dimensão dos canais, integrando informações de diferentes escalas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vzPQX3XDEENC",
      "metadata": {
        "id": "vzPQX3XDEENC"
      },
      "source": [
        "### Importando os módulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cf548246",
      "metadata": {
        "id": "cf548246"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3jGtP_jDEQpy",
      "metadata": {
        "id": "3jGtP_jDEQpy"
      },
      "source": [
        "#### Criando o modelo de módulo de inserção com redução de dimensões"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dbf242d5",
      "metadata": {
        "id": "dbf242d5"
      },
      "outputs": [],
      "source": [
        "\n",
        "class InsercaoModulo(nn.Module):\n",
        "    def __init__(self, in_channels=3, reduced_channels=2, out_channels=32):\n",
        "        super(InsercaoModulo, self).__init__()\n",
        "\n",
        "        # Redução de Dimensão com Convolução 1x1\n",
        "        self.reduction = nn.Conv2d(in_channels, reduced_channels, kernel_size=1)\n",
        "\n",
        "        # Convolução 1x1 após redução\n",
        "        self.conv1x1 = nn.Conv2d(reduced_channels, out_channels, kernel_size=1)\n",
        "\n",
        "        # Convolução 3x3 após redução\n",
        "        self.conv3x3 = nn.Conv2d(reduced_channels, out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "        # Convolução 5x5 após redução\n",
        "        self.conv5x5 = nn.Conv2d(reduced_channels, out_channels, kernel_size=5, padding=2)\n",
        "\n",
        "        # Max Pooling 3x3 seguido de convolução 1x1 após redução\n",
        "        self.maxpool3x3 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.conv_after_pooling = nn.Conv2d(reduced_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Aplicando a redução de dimensão\n",
        "        x_reduced = self.reduction(x)\n",
        "\n",
        "        # Aplicando cada uma das operações após a redução\n",
        "        conv1x1_out = self.conv1x1(x_reduced)\n",
        "        conv3x3_out = self.conv3x3(x_reduced)\n",
        "        conv5x5_out = self.conv5x5(x_reduced)\n",
        "        maxpool_out = self.conv_after_pooling(self.maxpool3x3(x_reduced))\n",
        "\n",
        "        # Concatenando as saídas ao longo da dimensão dos canais\n",
        "        out = torch.cat([conv1x1_out, conv3x3_out, conv5x5_out, maxpool_out], dim=1)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Kg2b4GaR-EwJ",
      "metadata": {
        "id": "Kg2b4GaR-EwJ"
      },
      "source": [
        "### Exemplo de Utilização\n",
        "\n",
        "Vamos considerar um exemplo prático de como utilizar o módulo `InsercaoModulo`:\n",
        "\n",
        "1. **Número de Canais de Entrada**: 3 canais (por exemplo, uma imagem RGB).\n",
        "2. **Número de Canais Após Redução**: 2 canais, obtidos após a operação de redução de dimensão com uma convolução 1x1.\n",
        "3. **Número de Canais de Saída**: 32 canais para cada operação de convolução (1x1, 3x3 e 5x5) e após a operação de max pooling com convolução adicional."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2860eef3",
      "metadata": {
        "id": "2860eef3"
      },
      "source": [
        "\n",
        "### Teste\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Vamos agora testar o módulo `InsercaoModulo` com um tensor de entrada que simula uma imagem RGB (com 3 canais). Vamos observar a forma da saída após passar pelo módulo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "F75lkdX2922K",
      "metadata": {
        "id": "F75lkdX2922K"
      },
      "outputs": [],
      "source": [
        "in_channels = 3  # Número de canais de entrada (3 para uma imagem RGB)\n",
        "reduced_channels = 2  # Número de canais após a redução\n",
        "out_channels = 32  # Número de canais de saída por cada operação de convolução\n",
        "\n",
        "model = InsercaoModulo(in_channels, reduced_channels, out_channels)\n",
        "input_tensor = torch.randn(1, in_channels, 32, 32)  # Um tensor de entrada de exemplo (batch size 1, 3 canais, 32x32 de dimensão)\n",
        "output = model(input_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8qw3s9u6z5DH",
      "metadata": {
        "id": "8qw3s9u6z5DH"
      },
      "source": [
        "O valor de saída é:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6XkaUo79z9Le",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XkaUo79z9Le",
        "outputId": "626bb6a4-5b94-4c93-b863-42b15d695bfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 128, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Dvi4qHSo72uO",
      "metadata": {
        "id": "Dvi4qHSo72uO"
      },
      "source": [
        " ## Classificadores Auxiliares\n",
        "\n",
        "\n",
        "Auxiliary classifiers, ou classificadores auxiliares, são componentes adicionais em uma rede neural projetada para ajudar a melhorar o desempenho do modelo principal. Eles são usados para realizar tarefas secundárias que estão relacionadas à tarefa principal, mas não são a tarefa principal em si. Esses classificadores podem ter várias finalidades, como melhorar a qualidade das representações aprendidas, fornecer regularização ou incentivar a rede a aprender características mais robustas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UqdlagEmF-95",
      "metadata": {
        "id": "UqdlagEmF-95"
      },
      "source": [
        "### Importando os módulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "OEu28k_O83Vk",
      "metadata": {
        "id": "OEu28k_O83Vk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6KlUQRNd_fj5",
      "metadata": {
        "id": "6KlUQRNd_fj5"
      },
      "source": [
        " ### Criando um exemplo de rede neural que possui um classificador auxiliar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Grh_0nlo84o_",
      "metadata": {
        "id": "Grh_0nlo84o_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Definindo a Rede Principal com Classificador Auxiliar\n",
        "class DeepNetworkWithAuxiliary(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(DeepNetworkWithAuxiliary, self).__init__()\n",
        "\n",
        "        # Camadas iniciais da rede\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        # Camada intermediária onde aplicaremos o classificador auxiliar\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "\n",
        "        # Classificador Auxiliar\n",
        "        self.aux_classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "        # Camadas finais da rede\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "\n",
        "        # Passando pela camada intermediária\n",
        "        x = torch.relu(self.conv3(x))\n",
        "\n",
        "        # Extraindo a saída do classificador auxiliar\n",
        "        aux_output = self.aux_classifier(x)\n",
        "\n",
        "        # Continuando na rede principal\n",
        "        x = torch.relu(self.conv4(x))\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))  # Usando a função do módulo functional\n",
        "        x = torch.flatten(x, 1)\n",
        "        main_output = self.fc(x)\n",
        "\n",
        "        return main_output, aux_output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "erLlNCrZApEm",
      "metadata": {
        "id": "erLlNCrZApEm"
      },
      "source": [
        "### Criando a rede."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "H_nHiX8p_1nY",
      "metadata": {
        "id": "H_nHiX8p_1nY"
      },
      "outputs": [],
      "source": [
        "# Criando a rede e definindo a função de perda e otimizador\n",
        "model = DeepNetworkWithAuxiliary(num_classes=10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CzQNDAMhAtmb",
      "metadata": {
        "id": "CzQNDAMhAtmb"
      },
      "source": [
        "### Exemplo de uso\n",
        "\n",
        " Utilizando um batch aleatório de 16 imagens RGB 32x32 e 16 rótulos de classe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "MG_yuHzu-eSS",
      "metadata": {
        "id": "MG_yuHzu-eSS"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_tensor = torch.randn(16, 3, 32, 32)\n",
        "labels = torch.randint(0, 10, (16,))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7FG4yQYPBEuX",
      "metadata": {
        "id": "7FG4yQYPBEuX"
      },
      "source": [
        "## Treino\n",
        "\n",
        "Utilizando o valor  0.4 para a perda auxiliar, vamos realizar o treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "yVBU3y8c-l0P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVBU3y8c-l0P",
        "outputId": "5400e472-27a9-4f1d-f00b-d30415697967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saída principal do modelo: tensor([[-0.0340, -0.0190, -0.0407, -0.0161, -0.0114,  0.0136,  0.0263,  0.0038,\n",
            "         -0.0248, -0.0262],\n",
            "        [-0.0344, -0.0194, -0.0406, -0.0155, -0.0113,  0.0139,  0.0265,  0.0037,\n",
            "         -0.0248, -0.0260],\n",
            "        [-0.0344, -0.0197, -0.0403, -0.0149, -0.0117,  0.0135,  0.0267,  0.0044,\n",
            "         -0.0244, -0.0259],\n",
            "        [-0.0345, -0.0189, -0.0406, -0.0155, -0.0117,  0.0134,  0.0268,  0.0040,\n",
            "         -0.0243, -0.0260],\n",
            "        [-0.0346, -0.0194, -0.0405, -0.0158, -0.0112,  0.0135,  0.0265,  0.0041,\n",
            "         -0.0244, -0.0259],\n",
            "        [-0.0341, -0.0190, -0.0410, -0.0153, -0.0110,  0.0134,  0.0266,  0.0036,\n",
            "         -0.0243, -0.0263],\n",
            "        [-0.0344, -0.0188, -0.0411, -0.0156, -0.0110,  0.0131,  0.0267,  0.0037,\n",
            "         -0.0245, -0.0261],\n",
            "        [-0.0344, -0.0189, -0.0407, -0.0156, -0.0117,  0.0127,  0.0265,  0.0042,\n",
            "         -0.0240, -0.0261],\n",
            "        [-0.0345, -0.0190, -0.0405, -0.0153, -0.0115,  0.0134,  0.0265,  0.0042,\n",
            "         -0.0244, -0.0258],\n",
            "        [-0.0346, -0.0196, -0.0406, -0.0151, -0.0110,  0.0137,  0.0264,  0.0035,\n",
            "         -0.0243, -0.0264],\n",
            "        [-0.0344, -0.0189, -0.0403, -0.0154, -0.0117,  0.0134,  0.0264,  0.0040,\n",
            "         -0.0244, -0.0258],\n",
            "        [-0.0344, -0.0192, -0.0402, -0.0157, -0.0117,  0.0139,  0.0264,  0.0048,\n",
            "         -0.0242, -0.0255],\n",
            "        [-0.0344, -0.0189, -0.0414, -0.0157, -0.0107,  0.0135,  0.0266,  0.0032,\n",
            "         -0.0246, -0.0265],\n",
            "        [-0.0346, -0.0186, -0.0409, -0.0156, -0.0111,  0.0137,  0.0264,  0.0037,\n",
            "         -0.0244, -0.0262],\n",
            "        [-0.0342, -0.0195, -0.0404, -0.0155, -0.0117,  0.0138,  0.0266,  0.0042,\n",
            "         -0.0247, -0.0253],\n",
            "        [-0.0342, -0.0194, -0.0407, -0.0159, -0.0111,  0.0136,  0.0263,  0.0041,\n",
            "         -0.0243, -0.0259]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "saída auxiliar do modelo: tensor([[ 0.0203,  0.0330,  0.0322,  0.0416,  0.0224, -0.0422, -0.0618, -0.1116,\n",
            "          0.0379,  0.0971],\n",
            "        [ 0.0186,  0.0324,  0.0317,  0.0401,  0.0227, -0.0423, -0.0624, -0.1100,\n",
            "          0.0380,  0.0967],\n",
            "        [ 0.0175,  0.0317,  0.0315,  0.0396,  0.0221, -0.0418, -0.0621, -0.1095,\n",
            "          0.0386,  0.0955],\n",
            "        [ 0.0182,  0.0313,  0.0314,  0.0421,  0.0234, -0.0405, -0.0623, -0.1103,\n",
            "          0.0380,  0.0979],\n",
            "        [ 0.0187,  0.0325,  0.0315,  0.0408,  0.0224, -0.0416, -0.0617, -0.1096,\n",
            "          0.0381,  0.0965],\n",
            "        [ 0.0187,  0.0322,  0.0307,  0.0412,  0.0209, -0.0403, -0.0628, -0.1104,\n",
            "          0.0389,  0.0979],\n",
            "        [ 0.0185,  0.0326,  0.0319,  0.0412,  0.0211, -0.0406, -0.0629, -0.1110,\n",
            "          0.0381,  0.0976],\n",
            "        [ 0.0169,  0.0319,  0.0318,  0.0416,  0.0201, -0.0395, -0.0632, -0.1110,\n",
            "          0.0387,  0.0981],\n",
            "        [ 0.0185,  0.0310,  0.0315,  0.0401,  0.0213, -0.0422, -0.0626, -0.1102,\n",
            "          0.0373,  0.0964],\n",
            "        [ 0.0182,  0.0332,  0.0309,  0.0397,  0.0223, -0.0415, -0.0624, -0.1105,\n",
            "          0.0388,  0.0959],\n",
            "        [ 0.0188,  0.0327,  0.0314,  0.0390,  0.0219, -0.0430, -0.0623, -0.1099,\n",
            "          0.0366,  0.0956],\n",
            "        [ 0.0188,  0.0306,  0.0313,  0.0413,  0.0207, -0.0421, -0.0616, -0.1089,\n",
            "          0.0383,  0.0959],\n",
            "        [ 0.0196,  0.0330,  0.0301,  0.0427,  0.0224, -0.0406, -0.0615, -0.1121,\n",
            "          0.0396,  0.1000],\n",
            "        [ 0.0185,  0.0320,  0.0314,  0.0418,  0.0214, -0.0416, -0.0621, -0.1111,\n",
            "          0.0384,  0.0971],\n",
            "        [ 0.0183,  0.0309,  0.0316,  0.0406,  0.0223, -0.0426, -0.0619, -0.1088,\n",
            "          0.0382,  0.0971],\n",
            "        [ 0.0191,  0.0315,  0.0318,  0.0408,  0.0214, -0.0420, -0.0621, -0.1094,\n",
            "          0.0375,  0.0967]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Perda total: 3.225088596343994\n",
            "Perda Auxiliar: 2.298985719680786\n"
          ]
        }
      ],
      "source": [
        "\n",
        "optimizer.zero_grad()\n",
        "main_output, aux_output = model(input_tensor)\n",
        "loss_main = criterion(main_output, labels)\n",
        "loss_aux = criterion(aux_output, labels)\n",
        "total_loss = loss_main + 0.4 * loss_aux\n",
        "total_loss.backward()\n",
        "optimizer.step()\n",
        "print(\"saída principal do modelo:\", main_output)\n",
        "print('')\n",
        "print(\"saída auxiliar do modelo:\",aux_output)\n",
        "print('')\n",
        "print(\"Perda total:\", total_loss.item())\n",
        "print(\"Perda Auxiliar:\",loss_aux.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tmeU6pqD3AhO",
      "metadata": {
        "id": "tmeU6pqD3AhO"
      },
      "source": [
        "### Calcular a acurácia do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "BYjnN3Hy26yv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYjnN3Hy26yv",
        "outputId": "17120e36-7826-4ed5-ca83-da310e49452a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisão: 0.0625\n"
          ]
        }
      ],
      "source": [
        "_, predicted = torch.max(main_output, 1)\n",
        "correct = (predicted == labels).sum().item()\n",
        "total = labels.size(0)\n",
        "accuracy = correct / total\n",
        "print(\"Precisão:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
